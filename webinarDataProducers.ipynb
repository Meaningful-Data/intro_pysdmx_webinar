{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a32e2eb94c19ca5d",
   "metadata": {},
   "source": ""
  },
  {
   "cell_type": "markdown",
   "id": "5ce654850edb5602",
   "metadata": {},
   "source": [
    "# Outside the SDMX garden, looking at LEI and GLEIF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8795d1c0a1dfe4",
   "metadata": {},
   "source": [
    "The Legal Entity Identifier (LEI) is a unique global identifier for legal entities participating in financial transactions. Its purpose is to help identify legal entities on a globally accessible database (source [Wikipedia](https://en.wikipedia.org/wiki/Legal_Entity_Identifier)).\n",
    "\n",
    "The Global LEI Foundation (GLEIF) supports the implementation and use of the LEI. It makes it possible to access all the LEI records through APIs or downloading file.\n",
    "\n",
    "The GLEIF site does not use SDMX. It maintains a [data dictionary](https://www.gleif.org/en/lei-data/access-and-use-lei-data/gleif-data-dictionary) and [an API](https://www.gleif.org/en/lei-data/gleif-api). It also makes possible downloading [golden copies of the data, as well as delta files](https://www.gleif.org/en/lei-data/gleif-golden-copy).\n",
    "\n",
    "\n",
    "As relevant master data about entities, a good integration with the GLEIF data may be in the interest of many institutions.\n",
    "For institutions having SDMX-driven system, it may be useful to create SDMX metadata and convert the LEI data from their source formats to SDMX, so that they can be integrated int their systems. Besides, it may be useful for those entities to validate the input data an generate new statistics.\n",
    "\n",
    "This notebook is presenting a way to use pysdmx and the VTL Engine to represent a statistical process that includes:\n",
    "1. The collection of data from the GLEIF\n",
    "2. The transformation of data into SDMX\n",
    "3. The structural validation of data using FMR\n",
    "4. The consistency validation of the data using VTL\n",
    "5. The generation of new aggregated statistics using VTL\n",
    "6. The conversion of the data into SDMX\n",
    "\n",
    "![Agenda](agenda.png)\n",
    "\n",
    "\n",
    "For this exercise, the necessary SDMX metadata have been added to an FMR instance hosted by Meaningfuldata (https://fmr.meaningfuldata.eu/)\n",
    "\n",
    "### List of pysdmx classes and functions used in this notebook:\n",
    "\n",
    "Functions:\n",
    "- pysdmx.io.read_sdmx\n",
    "- pysdmx.io.csv.sdmx20.writer.write\n",
    "\n",
    "Classes:\n",
    "- pysdmx.api.fmr.RegistryClient (and methods)\n",
    "- pysdmx.model.message.Message (and methods)\n",
    "- pysdmx.io.pd.PandasDataset\n",
    "- pysdmx.model.dataflow.Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f0ec891c33d0c2",
   "metadata": {},
   "source": [
    "## Data cleaning and set up using pandas and pysdmx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62e158b6618a05e",
   "metadata": {},
   "source": [
    "For this exercise, we will use as input the [golden copy from the GLEIF](https://www.gleif.org/en/lei-data/gleif-golden-copy/download-the-golden-copy#/), and we will transform it to get a dataset following the desired data structure, which can be fournd [here](https://fmr.meaningfuldata.eu/sdmx/v2/structure/datastructure/MD/LEI_DATA/1.0).\n",
    "\n",
    "Note that we designed this DSD from the existing data, but took a subset of the data and renamed the attributes to make them closer to SDMX practices.\n",
    "\n",
    "We are using Pandas to read the original data and to transform them to get a final dataset that follows the DSD.\n",
    "\n",
    "The steps are:\n",
    "\n",
    "1. Download the data from [the source](https://www.gleif.org/en/lei-data/gleif-golden-copy/download-the-golden-copy#.zip)\n",
    "2. Read the downloaded data with Pandas\n",
    "3. Drop the columns not used in the DSD and rename the existing ones\n",
    "4. Filter to get only the active entities (the GLEIF publishes also inactive entities)\n",
    "\n",
    "The code includes a function that uses the chunking capabilities of Pandas for better memory efficiency.\n",
    "This is a prototype of data streaming in pysdmx,\n",
    "which will be available by the end of 2025.\n",
    "\n",
    "This code requires to install the extra data from pysdmx,\n",
    "which simply install pandas.\n",
    "\n",
    "```bash\n",
    "pip install pysdmx[data]\n",
    "```\n",
    "\n",
    "The size of the original CSV file is almost 4GB.\n",
    "We have run the example with the full dataset, getting the same results that are shown now.\n",
    "Handling efficiently large datasets is in the roadmap of pysdmx, but not yet implemented.\n",
    "For this reason, and for the live demo, we are using a subset of the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "id": "e47710901a4724a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T12:38:21.475577Z",
     "start_time": "2025-01-27T12:37:58.317885Z"
    }
   },
   "source": [
    "from utils import streaming_load_save_csv_file\n",
    "\n",
    "import requests\n",
    "import zipfile\n",
    "#1. Download the Golden Copy file\n",
    "\n",
    "GOLDEN_COPY_PATH = 'data_files/lei_golden_copy'\n",
    "\n",
    "url = 'https://leidata-preview.gleif.org/storage/golden-copy-files/2025/01/25/1034569/20250125-1600-gleif-goldencopy-lei2-golden-copy.csv.zip'\n",
    "r = requests.get(url)\n",
    "\n",
    "with open(GOLDEN_COPY_PATH + '.zip', 'wb') as f:\n",
    "    f.write(r.content)\n",
    "\n",
    "with zipfile.ZipFile(GOLDEN_COPY_PATH + '.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('data_files/')\n",
    "    file_name = zip_ref.namelist()[0]\n",
    "\n",
    "# file_name = '20250125-1600-gleif-goldencopy-lei2-golden-copy.csv'\n",
    "\n",
    "#2. Read the downloaded data with Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# We will read only the first 10000 rows as a sample\n",
    "data = pd.read_csv('data_files/' + file_name, dtype=str, nrows=10000)\n",
    "\n",
    "#3. Drop the columns not used in the DSD and rename the existing ones\n",
    "\n",
    "RENAME_DICT = {\n",
    "    \"LEI\": \"LEI\",\n",
    "    \"Entity.LegalName\": \"LEGAL_NAME\",\n",
    "    \"Entity.LegalAddress.Country\": \"COUNTRY_INCORPORATION\",\n",
    "    \"Entity.HeadquartersAddress.Country\": \"COUNTRY_HEADQUARTERS\",\n",
    "    \"Entity.EntityCategory\": \"CATEGORY\",\n",
    "    \"Entity.EntitySubCategory\": \"SUBCATEGORY\",\n",
    "    \"Entity.LegalForm.EntityLegalFormCode\": \"LEGAL_FORM\",\n",
    "    \"Entity.EntityStatus\": \"STATUS\",\n",
    "    \"Entity.LegalAddress.PostalCode\": \"POSTAL_CODE\",\n",
    "}\n",
    "\n",
    "data.rename(columns=RENAME_DICT, inplace=True)\n",
    "data = data[list(RENAME_DICT.values())]\n",
    "\n",
    "# 4. Data filtering by status\n",
    "data = data[data['STATUS'] == 'ACTIVE'].reset_index(drop=True)\n",
    "del data['STATUS']\n",
    "display(data)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                       LEI                                         LEGAL_NAME  \\\n",
       "0     001GPB6A9XPE8XJICC14      Fidelity Advisor Leveraged Company Stock Fund   \n",
       "1     004L5FPTUREIWK9T2N63                           Hutchin Hill Capital, LP   \n",
       "2     00EHHQ2ZHDCFXJCPCL46           Vanguard Russell 1000 Growth Index Trust   \n",
       "3     00GBW0Z2GYIER7DHDS71                           ARISTEIA CAPITAL, L.L.C.   \n",
       "4     00KLB2PFTM3060S2N216                         Oakmark International Fund   \n",
       "...                    ...                                                ...   \n",
       "9549  21380012PY96FUKPP805                                   ITELA HOLDING AS   \n",
       "9550  21380012Q6KHP17Q4K39                      JOSEPH WALTER CHAMBERLAIN DIS   \n",
       "9551  21380012QLF2BOUUZA18  R W ARMSTRONG & SONS LIMITED RETIREMENT AND DE...   \n",
       "9552  21380012QWUG4B14Y756                    ORIENTAL HARBOR INVESTMENT FUND   \n",
       "9553  21380012QZAV5QDFMW29                                     DEMPSTER TRUST   \n",
       "\n",
       "     COUNTRY_INCORPORATION COUNTRY_HEADQUARTERS CATEGORY SUBCATEGORY  \\\n",
       "0                       US                   US     FUND         NaN   \n",
       "1                       US                   US  GENERAL         NaN   \n",
       "2                       US                   US     FUND         NaN   \n",
       "3                       US                   US  GENERAL         NaN   \n",
       "4                       US                   US     FUND         NaN   \n",
       "...                    ...                  ...      ...         ...   \n",
       "9549                    NO                   NO  GENERAL         NaN   \n",
       "9550                    GB                   GB  GENERAL         NaN   \n",
       "9551                    GB                   GB  GENERAL         NaN   \n",
       "9552                    KY                   HK  GENERAL         NaN   \n",
       "9553                    GB                   GB  GENERAL         NaN   \n",
       "\n",
       "     LEGAL_FORM POSTAL_CODE  \n",
       "0          8888       02210  \n",
       "1          T91T       19808  \n",
       "2          8888       19355  \n",
       "3          HZEH       19801  \n",
       "4          8888       02110  \n",
       "...         ...         ...  \n",
       "9549       YI42        0191  \n",
       "9550       8888     BS2 0PT  \n",
       "9551       8888    RG26 5RU  \n",
       "9552       MPUG    KY1-1206  \n",
       "9553       8888     GU9 8DG  \n",
       "\n",
       "[9554 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LEI</th>\n",
       "      <th>LEGAL_NAME</th>\n",
       "      <th>COUNTRY_INCORPORATION</th>\n",
       "      <th>COUNTRY_HEADQUARTERS</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>SUBCATEGORY</th>\n",
       "      <th>LEGAL_FORM</th>\n",
       "      <th>POSTAL_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001GPB6A9XPE8XJICC14</td>\n",
       "      <td>Fidelity Advisor Leveraged Company Stock Fund</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>FUND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8888</td>\n",
       "      <td>02210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004L5FPTUREIWK9T2N63</td>\n",
       "      <td>Hutchin Hill Capital, LP</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T91T</td>\n",
       "      <td>19808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00EHHQ2ZHDCFXJCPCL46</td>\n",
       "      <td>Vanguard Russell 1000 Growth Index Trust</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>FUND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8888</td>\n",
       "      <td>19355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00GBW0Z2GYIER7DHDS71</td>\n",
       "      <td>ARISTEIA CAPITAL, L.L.C.</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HZEH</td>\n",
       "      <td>19801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00KLB2PFTM3060S2N216</td>\n",
       "      <td>Oakmark International Fund</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>FUND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8888</td>\n",
       "      <td>02110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9549</th>\n",
       "      <td>21380012PY96FUKPP805</td>\n",
       "      <td>ITELA HOLDING AS</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YI42</td>\n",
       "      <td>0191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9550</th>\n",
       "      <td>21380012Q6KHP17Q4K39</td>\n",
       "      <td>JOSEPH WALTER CHAMBERLAIN DIS</td>\n",
       "      <td>GB</td>\n",
       "      <td>GB</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8888</td>\n",
       "      <td>BS2 0PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9551</th>\n",
       "      <td>21380012QLF2BOUUZA18</td>\n",
       "      <td>R W ARMSTRONG &amp; SONS LIMITED RETIREMENT AND DE...</td>\n",
       "      <td>GB</td>\n",
       "      <td>GB</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8888</td>\n",
       "      <td>RG26 5RU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9552</th>\n",
       "      <td>21380012QWUG4B14Y756</td>\n",
       "      <td>ORIENTAL HARBOR INVESTMENT FUND</td>\n",
       "      <td>KY</td>\n",
       "      <td>HK</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MPUG</td>\n",
       "      <td>KY1-1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9553</th>\n",
       "      <td>21380012QZAV5QDFMW29</td>\n",
       "      <td>DEMPSTER TRUST</td>\n",
       "      <td>GB</td>\n",
       "      <td>GB</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8888</td>\n",
       "      <td>GU9 8DG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9554 rows Ã— 8 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "id": "2354d3dbf10e8fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T12:38:21.480095Z",
     "start_time": "2025-01-27T12:38:21.476608Z"
    }
   },
   "source": [
    "# Load and save using chunks (if memory is a problem). Reading the output afterwards\n",
    "# streaming_load_save_csv_file('data_files/' + file_name, 'data_files/' + \"golden_copy_changed.csv\", use_sdmx_csv=False)\n",
    "# data = pd.read_csv('data_files/' + \"golden_copy_changed.csv\", dtype=str)"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "id": "e669b8a683583bfc",
   "metadata": {},
   "source": [
    "# Generate the pysdmx dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee14d288997e4000",
   "metadata": {},
   "source": [
    "## Retrieving the Schema from FMR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d713bc0ad0a4400c",
   "metadata": {},
   "source": [
    "Using the Registry Client, we download the Schema from FMR, using the FusionJSON format."
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T12:52:34.393279Z",
     "start_time": "2025-01-27T12:52:33.636155Z"
    }
   },
   "source": [
    "from pysdmx.api.fmr import RegistryClient\n",
    "from pysdmx.io.format import StructureFormat\n",
    "\n",
    "client = RegistryClient(\n",
    "    \"https://fmr.meaningfuldata.eu/sdmx/v2\", format=StructureFormat.FUSION_JSON\n",
    ")\n",
    "# Recommend to use debugger to see the response\n",
    "schema = client.get_schema(\n",
    "    \"datastructure\", agency=\"MD\", id=\"LEI_DATA\", version=\"1.0\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 57
  },
  {
   "cell_type": "markdown",
   "id": "7a1cdedfe20a7b5f",
   "metadata": {},
   "source": "# Generate dataset and validate using FMR"
  },
  {
   "cell_type": "code",
   "id": "a7a9c79d87384195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T12:53:28.978540Z",
     "start_time": "2025-01-27T12:53:27.296669Z"
    }
   },
   "source": [
    "# Code to validate the dataset on FMR\n",
    "from utils import validate_data_fmr\n",
    "from pysdmx.io.csv.sdmx20.writer import write\n",
    "\n",
    "from pysdmx.io.pd import PandasDataset\n",
    "\n",
    "dataset = PandasDataset(structure=schema, data=data)\n",
    "\n",
    "# Serialization on SDMX-CSV 2.0\n",
    "csv_text = write([dataset])\n",
    "\n",
    "result = validate_data_fmr(csv_text, host=\"fmr.meaningfuldata.eu\", port=443,\n",
    "                           use_https=True)\n",
    "result"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "markdown",
   "id": "d121d14434dd4d28",
   "metadata": {},
   "source": [
    "## Write data to a SDMX-CSV 2.0 file"
   ]
  },
  {
   "cell_type": "code",
   "id": "cee7ca6f99339c72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T12:54:03.078361Z",
     "start_time": "2025-01-27T12:54:03.043205Z"
    }
   },
   "source": [
    "from pysdmx.io.csv.sdmx20.writer import write\n",
    "\n",
    "output = write([dataset], \"data_files/golden_copy_changed_sdmx.csv\")"
   ],
   "outputs": [],
   "execution_count": 60
  },
  {
   "cell_type": "markdown",
   "id": "3f3374bb987f74c8",
   "metadata": {},
   "source": [
    "# Using VTL to validate the data with GLEIF data quality checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946c133de69a530",
   "metadata": {},
   "source": [
    "The VTL language allows us to perform validations over the data,\n",
    "with a business friendly syntax.\n",
    "While SDMX allows to make validations using the metadata,\n",
    "VTL broadens the possibilities of validations\n",
    "by defining rules that generate conditions over which the data is valid,\n",
    "and combining the errors into a single dataset.\n",
    "\n",
    "For this purpose,\n",
    "at MeaningfulData we have developed a library called vtlengine,\n",
    "part of our own VTL Suite.\n",
    "\n",
    "In this example,\n",
    "we will use a VTL script\n",
    "that performs validations based on the GLEIF [data quality checks](https://www.gleif.org/en/lei-data/gleif-data-quality-management/data-quality-checks) and a custom validation on Subcategory data.\n",
    "\n",
    "Steps to use VTL from pysdmx:\n",
    "1. Convert the Schema to a VTL DataStructure\n",
    "2. Validate the data using VTL (with vtlengine library)\n",
    "3. Analyse the results and write to a SDMX file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c338d2e18812b045",
   "metadata": {},
   "source": [
    "## Convert the Schema to a VTL DataStructure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163d8b1bb245a5c0",
   "metadata": {},
   "source": [
    "This code converts the pysdmx.model Schema and DataStructureDefinition objects into a VTL datastructure,\n",
    "using MeaningfulData internal format, usable only with vtlengine.\n",
    "On pysdmx we will include this method\n",
    "but it will generate the VTL 2.1 Standard datastructure.\n",
    "Both options will be usable by the vtlengine library."
   ]
  },
  {
   "cell_type": "code",
   "id": "47d0aa10345373df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T12:54:09.357748Z",
     "start_time": "2025-01-27T12:54:09.352450Z"
    }
   },
   "source": [
    "from utils import to_vtl_json\n",
    "\n",
    "vtl_datastructure = to_vtl_json(schema)\n",
    "vtl_datastructure"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datasets': [{'name': 'LEI_DATA',\n",
       "   'DataStructure': [{'name': 'LEI',\n",
       "     'role': 'Identifier',\n",
       "     'type': 'String',\n",
       "     'nullable': False},\n",
       "    {'name': 'POSTAL_CODE',\n",
       "     'role': 'Measure',\n",
       "     'type': 'String',\n",
       "     'nullable': True},\n",
       "    {'name': 'COUNTRY_INCORPORATION',\n",
       "     'role': 'Measure',\n",
       "     'type': 'String',\n",
       "     'nullable': True},\n",
       "    {'name': 'COUNTRY_HEADQUARTERS',\n",
       "     'role': 'Measure',\n",
       "     'type': 'String',\n",
       "     'nullable': True},\n",
       "    {'name': 'CATEGORY',\n",
       "     'role': 'Measure',\n",
       "     'type': 'String',\n",
       "     'nullable': True},\n",
       "    {'name': 'SUBCATEGORY',\n",
       "     'role': 'Measure',\n",
       "     'type': 'String',\n",
       "     'nullable': True},\n",
       "    {'name': 'LEGAL_FORM',\n",
       "     'role': 'Measure',\n",
       "     'type': 'String',\n",
       "     'nullable': True},\n",
       "    {'name': 'LEGAL_NAME',\n",
       "     'role': 'Attribute',\n",
       "     'type': 'String',\n",
       "     'nullable': True}]}]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "cell_type": "markdown",
   "id": "27033a888adf030",
   "metadata": {},
   "source": [
    "## Validate the data using VTL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e00e96a0d8eb68",
   "metadata": {},
   "source": [
    "This process will execute the VTL Script \"validations.vtl\"\n",
    "on the generated data.\n",
    "The script will perform the following validations:\n",
    "\n",
    "1. Check the Postal Code format is valid for a specific country, stored on dataset \"validation.postal_code_errors\"\n",
    "2. Check the SubCategory is null when the Category is not \"RESIDENT_GOVERNMENT_ENTITY\", stored on dataset \"validation.subcategories_errors\"\n",
    "3. Check the SubCategory is not null when the Category is \"RESIDENT_GOVERNMENT_ENTITY\", stored on dataset \"validation.subcategories_errors\"\n",
    "4. Merging the errors into a single dataset, named \"errors_count\"\n",
    "\n",
    "We have considered that any error with level 1 is a warning,\n",
    "while any error with level 3 is a critical error\n",
    "and data therefore is not valid.\n",
    "\n",
    "For more details on the run method, [please visit](https://docs.vtlengine.meaningfuldata.eu/api.html#api)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b6c4a5fbb1cefc",
   "metadata": {},
   "source": [
    "## Running the VTL script"
   ]
  },
  {
   "cell_type": "code",
   "id": "2f848e828a5a3ccb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T12:38:24.466455Z",
     "start_time": "2025-01-27T12:38:24.466455Z"
    }
   },
   "source": [
    "from utils import _load_script\n",
    "from vtlengine import run\n",
    "\n",
    "script = _load_script(\"vtl/validations.vtl\")\n",
    "datapoints = {\"LEI_DATA\": data}\n",
    "\n",
    "validations_result = run(script=script, data_structures=vtl_datastructure,\n",
    "                         datapoints=datapoints)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "711d3b08dba1ffe7",
   "metadata": {},
   "source": [
    "### Getting the total number of errors"
   ]
  },
  {
   "cell_type": "code",
   "id": "8637c1a26593e8d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T12:38:24.467618Z",
     "start_time": "2025-01-27T12:38:24.467618Z"
    }
   },
   "source": [
    "validations_result['errors_count'].data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cdd69459b3926666",
   "metadata": {},
   "source": [
    "### Analysing data on Postal Code errors"
   ]
  },
  {
   "cell_type": "code",
   "id": "d5f70e21874acd8",
   "metadata": {},
   "source": [
    "cols_to_analyse = ['COUNTRY_INCORPORATION', 'POSTAL_CODE', 'errorcode', 'errorlevel']\n",
    "validations_result['validation.postal_codes_errors'].data[cols_to_analyse]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "63e6c09dae75a208",
   "metadata": {},
   "source": [
    "### Analysing data on Subcategory errors"
   ]
  },
  {
   "cell_type": "code",
   "id": "c313bba6c3c7e2fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T12:38:24.470141Z",
     "start_time": "2025-01-27T12:38:24.468630Z"
    }
   },
   "source": [
    "cols_to_analyse = ['CATEGORY', 'SUBCATEGORY', 'errorcode', 'errorlevel']\n",
    "validations_result['validation.subcategories_errors'].data[cols_to_analyse]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8ea685c47091461f",
   "metadata": {},
   "source": [
    "## Using VTL to perform calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e771f668bd6e5674",
   "metadata": {},
   "source": [
    "We have designed a VTL script that performs the following calculations:\n",
    "1. Count the number of entities that are incorporated in each country, stored in dataset \"calculation.number_incorporated_entities\"\n",
    "2. Count the number of entities with their headquarters located in each country, stored in dataset \"calculation.number_entities_different_hq\"\n",
    "3. Count the number of entities with their headquarters located in a different country than the one they are incorporated, stored in dataset \"calculation.number_entities_different_hq\"\n",
    "4. Join the three datasets into a single dataset, named \"lei_statistics\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4929e63554f557cb",
   "metadata": {},
   "source": [
    "## Running the VTL script"
   ]
  },
  {
   "cell_type": "code",
   "id": "146e83a27074f54",
   "metadata": {},
   "source": [
    "script = _load_script(\"vtl/calculations.vtl\")\n",
    "datapoints = {\"LEI_DATA\": data}\n",
    "\n",
    "calculations_result = run(script=script, data_structures=vtl_datastructure,\n",
    "                          datapoints=datapoints)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ed8d1f745c19c960",
   "metadata": {},
   "source": [
    "### Analysing the results"
   ]
  },
  {
   "cell_type": "code",
   "id": "daeb65e121b627a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T12:38:24.471154Z",
     "start_time": "2025-01-27T12:38:24.471154Z"
    }
   },
   "source": [
    "calculations_result['lei_statistics'].data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7e3c3a8534ebc635",
   "metadata": {},
   "source": "# Generate SDMX-ML file with the aggregated data"
  },
  {
   "cell_type": "markdown",
   "id": "8dbe210864a47037",
   "metadata": {},
   "source": [
    "Generate a PandasDataset from vtlengine output\n",
    "and use the SDMX-ML 2.1 Data write method from pysdmx.\n",
    "We will download the SDMX-ML 2.1 file with the DataStructureDefinition\n",
    "(with descendants).\n",
    "We convert the DataStructureDefinition into a Schema object and use it to create the PandasDataset.\n",
    "\n",
    "This code requires to install the extra data from pysdmx,\n",
    "which simply install pandas.\n",
    "\n",
    "```bash\n",
    "pip install pysdmx[xml]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecb69e95b71a9aa",
   "metadata": {},
   "source": [
    "## Getting the Schema from an URL using read_sdmx"
   ]
  },
  {
   "cell_type": "code",
   "id": "67c769825ddd09e8",
   "metadata": {},
   "source": [
    "from pysdmx.io import read_sdmx\n",
    "from pysdmx.io.pd import PandasDataset\n",
    "\n",
    "msg = read_sdmx(\n",
    "    \"https://fmr.meaningfuldata.eu/sdmx/v2/structure/datastructure/MD/LEI_AGGREGATE_STATISTICS/+/?format=sdmx-2.1&references=descendants&prettyPrint=true\")\n",
    "dsd = msg.get_data_structure_definition(\n",
    "    \"DataStructure=MD:LEI_AGGREGATE_STATISTICS(1.0)\")\n",
    "schema_aggregated = dsd.to_schema()\n",
    "data = calculations_result['lei_statistics'].data\n",
    "pd_dataset = PandasDataset(structure=schema_aggregated, data=data)\n",
    "pd_dataset"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d54b2cef79167cf5",
   "metadata": {},
   "source": [
    "### Write the SDMX-ML 2.1 file"
   ]
  },
  {
   "cell_type": "code",
   "id": "7b32b0deef8fe9f9",
   "metadata": {},
   "source": [
    "from pysdmx.io.xml.sdmx21.writer.structure_specific import write\n",
    "\n",
    "xml_str = write([pd_dataset], prettyprint=False)\n",
    "\n",
    "xml_str"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
